{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxWDncyvryi6"
      },
      "source": [
        "This notebook is part 1 of 3 jupyter notebooks that are made to build an AI tool that can help self-driving cars see.\n",
        "\n",
        "It's like this!! (Click on the image!)\n",
        "\n",
        "[<img src=\"https://i.ytimg.com/vi/2lxO_0FMalY/maxresdefault.jpg\" width=\"500\"/>](https://www.youtube.com/watch?v=9ydhDQaLAqM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847Nj57ZekeU"
      },
      "source": [
        "#@title Run this to download data and prepare our environment! { display-mode: \"form\" }\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "\n",
        "# Load data\n",
        "def load_cifar10():\n",
        "  (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = cifar10.load_data()\n",
        "  y_train_cifar = y_train_cifar.squeeze()\n",
        "  y_test_cifar = y_test_cifar.squeeze()\n",
        "  return (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar)\n",
        "\n",
        "# CIFAR100 classes\n",
        "idx_to_class = ['background', 'car', 'truck']\n",
        "\n",
        "# Construct vehicle dataset from CIFAR10\n",
        "def construct_vehicle_dataset(data, labels, images_per_class, label_car=1, label_truck=9):\n",
        "  mask_car = labels == label_car\n",
        "  mask_truck = labels == label_truck\n",
        "\n",
        "  mask_vehicles = mask_car | mask_truck\n",
        "  mask_background = np.invert(mask_vehicles)\n",
        "\n",
        "  data_car = data[mask_car]\n",
        "  data_truck = data[mask_truck]\n",
        "  data_background = data[mask_background][:images_per_class]\n",
        "\n",
        "  new_data = np.vstack((data_background, data_car, data_truck))\n",
        "  new_labels = np.repeat(np.array([0, 1, 2]), images_per_class, axis=0)\n",
        "\n",
        "  return new_data, new_labels\n",
        "\n",
        "def load_vehicle_dataset():\n",
        "  (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = load_cifar10()\n",
        "  x_train, y_train = construct_vehicle_dataset(x_train_cifar, y_train_cifar, 5000)\n",
        "  x_test, y_test = construct_vehicle_dataset(x_test_cifar, y_test_cifar, 1000)\n",
        "  return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "# Helper functions\n",
        "\n",
        "# plotting\n",
        "def plot_one_image(data, labels = [], index = None, image_shape = None):\n",
        "  '''\n",
        "  if data is a single image, display that image\n",
        "\n",
        "  if data is a 4d stack of images, display that image\n",
        "  '''\n",
        "  ### cv2.imshow('image', data)\n",
        "  num_dims   = len(data.shape)\n",
        "  num_labels = len(labels)\n",
        "  if image_shape is not None:\n",
        "    target_shape = image_shape\n",
        "  else:\n",
        "    target_shape = (32, 32, 3)\n",
        "  # reshape data if necessary\n",
        "  if num_dims == 1:\n",
        "    data = data.reshape(target_shape)\n",
        "  if num_dims == 2:\n",
        "    data = data.reshape(np.vstack[-1, image_shape])\n",
        "  num_dims   = len(data.shape)\n",
        "\n",
        "  # check if single or multiple images\n",
        "  if num_dims == 3:\n",
        "    if num_labels > 1:\n",
        "      print('Multiple labels does not make sense for single image.')\n",
        "      return\n",
        "\n",
        "    label = labels\n",
        "    if num_labels == 0:\n",
        "      label = ''\n",
        "    image = data\n",
        "\n",
        "  if num_dims == 4:\n",
        "    image = data[index, :]\n",
        "    label = labels[index]\n",
        "\n",
        "  # plot image of interest\n",
        "  print('Label: %s'%label)\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "def model_to_string(model):\n",
        "  import re\n",
        "  stringlist = []\n",
        "  model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "  sms = \"\\n\".join(stringlist)\n",
        "  sms = re.sub('_\\d\\d\\d','', sms)\n",
        "  sms = re.sub('_\\d\\d','', sms)\n",
        "  sms = re.sub('_\\d','', sms)\n",
        "  return sms\n",
        "\n",
        "def normalize(data):\n",
        "  # CIFAR100 mean (0.4914, 0.4822, 0.4465) std (0.2023, 0.1994, 0.2010)\n",
        "  return (data/255-np.array((0.4914, 0.4822, 0.4465))) / np.array((0.2023, 0.1994, 0.2010))\n",
        "\n",
        "def label_to_onehot(labels):\n",
        "  final_labels = np.zeros((len(labels), 3))\n",
        "  for i in range(len(labels)):\n",
        "    label = labels[i]\n",
        "    if label == 0:\n",
        "      final_labels[i,:] = np.array([1, 0, 0])\n",
        "    if label == 1:\n",
        "      final_labels[i,:] = np.array([0, 1, 0])\n",
        "    if label == 2:\n",
        "      final_labels[i,:] = np.array([0, 0, 1])\n",
        "  return final_labels\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "  history = history.history\n",
        "  history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "  history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "  best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "  if not ax:\n",
        "    f, ax = plt.subplots(1,1)\n",
        "  sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "  sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "  ax.axhline(0.333, linestyle = '--',color='red', label = 'Chance')\n",
        "  ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')\n",
        "  ax.legend(loc = 1)\n",
        "  ax.set_ylim([0.01, 1])\n",
        "\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel('Accuracy (Fraction)')\n",
        "\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am2Oe87hihZA"
      },
      "source": [
        "# Understanding our task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ULauRiUnva"
      },
      "source": [
        "##Self-driving cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL0PZLszVLsc"
      },
      "source": [
        "We'll start by understanding our problem through some questions:\n",
        "\n",
        "**What are potential benefits of self-driving cars?**\n",
        "\n",
        "Improved safety, increased productivity in driving properly, less road congestion, and fewer speeding tickets\n",
        "\n",
        "**How do self-driving cars work?**\n",
        "\n",
        "Via map building, path planning, and obstable avoidance\n",
        "\n",
        "**How do self-driving cars see?**\n",
        "\n",
        "Through a variety of solutions like radar, lidar, and camera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqm6BqAPwPFI"
      },
      "source": [
        "##Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryH-OYB7wdOX"
      },
      "source": [
        "\n",
        "- **Given an input image, what is the output of the object detection task?**\n",
        "\n",
        "  - **Object Detection**: Locate the presence of objects with a bounding box and types or classes of the located objects in an image.\n",
        "\n",
        "  - Output: One or more bounding boxes (e.g. defined by a point, width, and height), and a class label for each bounding box.\n",
        "\n",
        "\n",
        "- **Can we break this problem into some subtasks?**\n",
        "\n",
        "  - **Object Localization**: Locate the presence of objects in an image and indicate their location with a bounding box.\n",
        "\n",
        "  - Output: One or more bounding boxes (e.g. defined by a point, width, and height).\n",
        "\n",
        "  - **Image Classification / Object Recognition**: Predict the type or class of an object in an image.\n",
        "\n",
        "  - Output: A class label (e.g. one or more integers that are mapped to class labels).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIOd_yqVVxom"
      },
      "source": [
        "Today, we'll first start from building a image classifier which can recognize cars."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lb-mORcVaMI"
      },
      "source": [
        "# Understanding our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g94jZ8bIDvvh"
      },
      "source": [
        "## What data do we have?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1OYUQBoqAh1"
      },
      "source": [
        "One commonly used dataset for object recognition is CIFAR10. There are 10 classes in CIFAR10, including airplane, car, bird, cat, deer, dog, frog, horse, ship, truck.\n",
        "\n",
        "As we are trying to build a image classifier for self-driving cars, detecting cars is more of interest to us.\n",
        "\n",
        "Therefore, here we use a vehicle dataset, which contains the images in the car and truck categories, as well as some randomly chosen images from other categories in the CIFAR10 dataset.\n",
        "\n",
        "We use `load_vehicle_dataset()` to load the images in both the training set and the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qP5mLh7U00D"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_vehicle_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh4rmliVDaon"
      },
      "source": [
        "Here, `x` contains the images and `y` contains the corresponding class labels.\n",
        "\n",
        "Let's first get a better understanding of the dataset by looking into the labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUqNQ0hnCO6v"
      },
      "source": [
        "### Checking data labels/metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQK_cWxFD6Ix"
      },
      "source": [
        "`y_train` and `y_test` are 2 numpy arrays of our images' labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ9fBKusGXqY"
      },
      "source": [
        "The shape of a numpy array is stored in the `shape` attribute, so we can check the shape of the training set label by `y_train.shape`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5dlllnKEi96"
      },
      "source": [
        "print('Our labels are stored as %s in Python' % type(y_train))\n",
        "print('The label vector of the training set has dimensions of (%d, )' % y_train.shape)\n",
        "print('The label vector of the test set has dimensions of (%d, )' % y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYKKmeCl9_rl"
      },
      "source": [
        "Each object category is represented in a number as the label in the `y` vectors.\n",
        "\n",
        "Class names have been saved in the list `idx_to_class`, where the indices are the labels and the elements are class names. Eg. `idx_to_class[1]` is `car`, this means each `car` image has a label `1` in the `y` vector.\n",
        "\n",
        "We can print the whole list to check the 3 classes we have in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRjV7wFFCCzW"
      },
      "source": [
        "for i, class_name in enumerate(idx_to_class):\n",
        "  print('{} - {}'.format(i, class_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_N8hpXYIpT_"
      },
      "source": [
        "We also want to know how many images we have in each class. The `Counter` class in the `collections` package can count the occurrence of different elements for us. For example:\n",
        "\n",
        "```\n",
        "l = [1, 2, 3, 3, 4, 5, 5, 5]\n",
        "counter = collections.Counter(l)\n",
        "print(counter)\n",
        "```\n",
        "\n",
        "We can get:\n",
        "```\n",
        "Counter({5: 3, 3: 2, 1: 1, 2: 1, 4: 1})\n",
        "```\n",
        "\n",
        "We can use this in the code below to check the number of images we have in each object category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QnWHY668EVF"
      },
      "source": [
        "import collections\n",
        "\n",
        "counter_train = collections.Counter(y_train)\n",
        "print(counter_train)\n",
        "counter_test = collections.Counter(y_test)\n",
        "print(counter_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBHUX917wkeo"
      },
      "source": [
        "## What does our data look like?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uA4zJPqF1oC"
      },
      "source": [
        "Next, we'll take a look at the images in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDEDVcREGGfY"
      },
      "source": [
        "The images in the training and test sets are stored as numpy arrays in `x_train` and `x_test` respectively.\n",
        "\n",
        "Let us get the shape of these 2 arrays as what we did on the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf9lPZ8MH4Si"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iYXd67jIRsG"
      },
      "source": [
        "#@title Let's see what image shape represents! { display-mode: \"form\" }\n",
        "\n",
        "#@markdown What does the bold number (**15000**, 32, 32, 3) represent?\n",
        "Dimension_0  = \"number of images\" #@param [\"number of images\", \"image width\", \"image height\",\"number of colors\",\"fill in\"]\n",
        "\n",
        "#@markdown What does the bold number (15000, **32**, 32, 3) represent?\n",
        "Dimension_1  = \"image height\" #@param [\"number of images\", \"image width\", \"image height\",\"number of colors\",\"fill in\"]\n",
        "\n",
        "#@markdown What does the bold number (15000, 32, **32**, 3) represent?\n",
        "Dimension_2  = \"image width\" #@param [\"number of images\", \"image width\", \"image height\",\"number of colors\",\"fill in\"]\n",
        "\n",
        "#@markdown What does the bold number (15000, 32, 32, **3**) represent?\n",
        "Dimension_3  = \"number of colors\" #@param [\"number of images\", \"image width\", \"image height\",\"number of colors\",\"fill in\"]\n",
        "\n",
        "if Dimension_0 == 'number of images':\n",
        "  print(\"Yes! Dimension_0 is the number of images.\")\n",
        "else:\n",
        "  print(\"Try again for Dimension_0!\")\n",
        "\n",
        "if Dimension_1 == 'image height':\n",
        "  print(\"Yes! Dimension_1 is the height of the image.\")\n",
        "else:\n",
        "  print(\"Try again for Dimension_1!\")\n",
        "\n",
        "if Dimension_2 == 'image width':\n",
        "  print(\"Yes! Dimension_2 is the width of the image.\")\n",
        "else:\n",
        "  print(\"Try again for Dimension_2!\")\n",
        "\n",
        "if Dimension_3 == 'number of colors':\n",
        "  print(\"Yes! Dimension_3 stands for 3 colors - (r,g,b).\")\n",
        "else:\n",
        "  print(\"Try again for Dimension_3!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WxXax6-FkMj"
      },
      "source": [
        "Now, let's see a single image.\n",
        "\n",
        "The function `plot_one_image` can take in either one image or many images.\n",
        "\n",
        "```\n",
        "plot_one_image(data, labels)\n",
        "```\n",
        "\n",
        "where:\n",
        "* `data`: 1 or more images in one array\n",
        "* `labels`: the labels corresponding to the images in a list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tH-W_XCFwbC"
      },
      "source": [
        "# 0-4999 Background, 5000-9999 car, 10000-15000 truck\n",
        "\n",
        "image = x_train[5000]\n",
        "label = [idx_to_class[y_train[5000]]]\n",
        "plot_one_image(image, labels=label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuxN0RkihuB"
      },
      "source": [
        "Next, let's build an classifier using neural networks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AJzmg0drIYP"
      },
      "source": [
        "# Understanding and building Neural Networks (Perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYqvCKWpKfRM"
      },
      "source": [
        "### What are neural networks?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA1Rc_u3KoJT"
      },
      "source": [
        "Neural networks look something like this:\n",
        "\n",
        "![A 2 layer neural network](https://cdn-images-1.medium.com/max/1600/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q9S6SDcM8N9"
      },
      "source": [
        "Each orange and blue node is a neuron. The network itself is composed of a bunch of neurons that talk to each other and eventually give us a prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dik5yhBOERG"
      },
      "source": [
        "## Building networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E--8mjToZYBp"
      },
      "source": [
        "To build neural networks in Python, we use the packages known as `tensorflow` and `keras`. Let's learn how to build and use these networks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8PrEOTbhgNN"
      },
      "source": [
        "Tensorflow calls the various machine learning algorithms that it uses 'models'.  These 'models' are 'learning machines.''\n",
        "\n",
        "1. We **teach** models by **training** them on **data**.\n",
        "2. We **use** models to **predict** things.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqFAnQCxsgRm"
      },
      "source": [
        "# grab tools from our tensorflow and keras toolboxes!\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPOqTta1sb6e"
      },
      "source": [
        "Before we train the model or use it to predict something, we have to **create** the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yus22AQpsqMH"
      },
      "source": [
        "# create our model by specifying and compiling it\n",
        "model = Sequential()\n",
        "model.add(Dense(4, input_shape=(3,),activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "model.compile(loss='mean_squared_error',\n",
        "                optimizer='adam',\n",
        "                metrics=['mean_squared_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG3k7_983L1s"
      },
      "source": [
        "The things we'll want to pay most attention to as we go over how to build networks are:\n",
        "1. The number of neurons\n",
        "2. The activation of the neurons\n",
        "3. The losses and metrics\n",
        "\n",
        "Everything else will work with the default settings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "781M4IyhssuA"
      },
      "source": [
        "Let's walk though what each of these lines of code means!\n",
        "\n",
        "**1. Specify model**\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "```\n",
        "In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it.\n",
        "\n",
        "\n",
        "**2. Add layers to the network**\n",
        "```\n",
        "model.add(Dense(4,input_shape = (3,), activation = 'sigmoid'))\n",
        "```\n",
        "In this code, we `add` a `layer` of neurons to our network.\n",
        "\n",
        "This layers consists of 4 neurons. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layers outputs. We specify that there are 3 inputs here.\n",
        "\n",
        "We also specify what kind of output the neuron will give. If we want the neuron to output a number between 0 and 1 (like a probability!) we would use 'softmax' or 'sigmoid'. If we want the neuron to output any number, we can use 'linear'! we'll also often see 'relu', which is when a neuron will only output positive numbers.\n",
        "\n",
        "```\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "```\n",
        "This code adds ANOTHER layer to the network that has 1 neuron. This one neuron is used to predict a continuous value!\n",
        "\n",
        "**3. Turn the model on by compiling it**\n",
        "\n",
        "After having built the network, we want to train and use it, so we have to 'turn it on' and 'compile' it. To turn it on, we have to specify at the very least, a loss, an optimizer, and some ways of evaluating the model (metrics).\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "optimizer = 'adam',\n",
        "metrics = ['mean_squared_error'])\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toYjQUOVtKDT"
      },
      "source": [
        "Once we've created our network, we can use it very simply! Just like we did with sklearn, we define our input data (x), the true predictions from that data (y), and then train our model with `fit`.\n",
        "\n",
        "```\n",
        "model.fit(x, y)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aozkfBxtWa7"
      },
      "source": [
        "To use the model, we can use it to predict something with:\n",
        "```\n",
        "y = model.predict_classes(x)\n",
        "```\n",
        "\n",
        "We can actually use the model before we even train it! It just won't perform very well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlnni4nPyCA3"
      },
      "source": [
        "### A 2-Layer Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP5Z9cEMyBpM"
      },
      "source": [
        "\n",
        "We're going to build this model:\n",
        "\n",
        "![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxN_eHSoyBcF"
      },
      "source": [
        "This network can be described as:\n",
        "* Input Layer: 3\n",
        "* Layer 1 (Hidden): 4 neurons that are activated by `'relu'`\n",
        "* Layer 2 (Output): 2 neurons that are activated by `'softmax'`\n",
        "\n",
        "\n",
        "We also want to compile the model with\n",
        "`loss = 'categorical_crossentropy'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4rDgysgFtsC"
      },
      "source": [
        "# grab tools from our tensorflow and keras toolboxes!\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlVFP9lhJed-"
      },
      "source": [
        "model_1_answer = Sequential()\n",
        "model_1_answer.add(Dense(4, input_shape = (3,), activation = 'relu'))\n",
        "model_1_answer.add(Dense(2, activation = 'softmax'))\n",
        "model_1_answer.compile(loss='categorical_crossentropy',\n",
        "optimizer = 'adam',\n",
        "metrics = ['accuracy'])\n",
        "model_1 = model_1_answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH2UGOK4vuZ4"
      },
      "source": [
        "#@title Seeing whether our model is right!\n",
        "model_1_answer = Sequential()\n",
        "model_1_answer.add(Dense(4, input_shape = (3,), activation = 'relu'))\n",
        "model_1_answer.add(Dense(2, activation = 'softmax'))\n",
        "model_1_answer.compile(loss='categorical_crossentropy',\n",
        "optimizer = 'adam',\n",
        "metrics = ['accuracy'])\n",
        "\n",
        "if model_to_string(model_1) == model_to_string(model_1_answer):\n",
        "  print('Good job! Your model worked')\n",
        "else:\n",
        "  print('Please check your code again!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyLV1oHjT62K"
      },
      "source": [
        "# Applying Neural Networks to Recognizing Vehicles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBp4yqqoJF65"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD3Z0QamJF68"
      },
      "source": [
        "\n",
        "In our problem, we are given `images` of shape `(32, 32, 3)`, each assigned to one of 3 labels: car, truck, others. We want to identify the key things that we need to design our network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-7tm6ZlJF7G"
      },
      "source": [
        "## Building our custom neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8pozxKuJF7I"
      },
      "source": [
        "### Key Points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN4Pyw4qJF7N"
      },
      "source": [
        "We will build a simple 2-layer network for our first model!\n",
        "\n",
        "\n",
        "For our model, we have as our layers:\n",
        "* Input Layer:  However many inputs there are!\n",
        "* Layer 1 (Hidden): 128 neurons that are activated by `'relu'`\n",
        "* Layer 2 (Output): 3 neurons (1 per possible predicted class) that should have an appropriate activation.\n",
        "* We will compile with the `optimizers.SGD(lr=1e-3, momentum=0.9)` optimizer\n",
        "\n",
        "Regarding the output activation and the compilation loss, we know that:\n",
        "* Binary classification problems require an output activation of `'sigmoid'` and a loss of `'binary_cross_entropy'`\n",
        "* Multi-class classification problems require an output activation of `'softmax'` and a loss of `'categorical_crossentropy'`\n",
        "* Linear regression problems require an output activation of `'linear'` and a loss of `'mean_squared_error'`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzFTOYMiJF7Q"
      },
      "source": [
        "###Building the Model\n",
        "\n",
        "We need to remember the transformation we need to apply to our input (hint: flattening) to make it work with a multi-layer perceptron!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ea97XLsKG0G"
      },
      "source": [
        "perceptron = Sequential()\n",
        "perceptron.add(Flatten(input_shape = (32, 32, 3)))\n",
        "perceptron.add(Dense(units = 128, activation = 'relu'))\n",
        "perceptron.add(Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "perceptron.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i-xfhnaJF7q"
      },
      "source": [
        "#@title Let's see if our model is right! { display-mode: \"form\" }\n",
        "perceptron_answer = Sequential()\n",
        "perceptron_answer.add(Flatten(input_shape = (32, 32, 3)))\n",
        "perceptron_answer.add(Dense(units = 128, activation = 'relu'))\n",
        "perceptron_answer.add(Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "perceptron_answer.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if model_to_string(perceptron) == model_to_string(perceptron_answer):\n",
        "  print('Good job, you specified it correctly!')\n",
        "else:\n",
        "  print('Please check your code again!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nayBlbHmj4Ii"
      },
      "source": [
        "### Training our Perceptron\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AItvQJE5NY0H"
      },
      "source": [
        "Let's now train our perceptron on images from the train data!\n",
        "\n",
        "Unlike the models that we used in sklearn, our neural networks are pretty finnicky. Their performance depends a lot on *how much* they train. As we'll see, they usually get better with more training BUT actually can get worse with too much training. With too much training, our model can get overconfident in its abilities with the training manual (overfitting), and so doesn't actually think (generalize) when it is tested.\n",
        "\n",
        "The extra options in our `fit()` function pertain to how the neural networks train. Don't worry too much about the extra options, what really matters for us is that the right data is specified.\n",
        "\n",
        "To use `fit`, we use the following code:\n",
        "```\n",
        "history = perceptron.fit(train_data, train_labels, epochs = 10, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n",
        "```\n",
        "What are all these options?\n",
        "* `epochs`: how many times the model trains on the entire data set\n",
        "* `shuffle`: mixes the training dataset so the model pays better attention to the data and learns better while training\n",
        "* `validation_data`: we request that our model tests itself on the `test_data` after every epoch. Since our model is finnicky, instead of testing our model at the end of the training, we test it throughout.\n",
        "\n",
        " `history` gives us a data structure which allows us to plot the training and validation accuracy over time.\n",
        "\n",
        "We have one more option too:\n",
        "* `callbacks`: With a custom command, we tell our model to save the best version of itself to a model file called `model.h5`.\n",
        "\n",
        "\n",
        "Let's try this out!\n",
        "\n",
        "**Specifically, we'll load in the training and testing data and then train our MLP model.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s41zgK7lFQtT"
      },
      "source": [
        "Before training the model, we need to preprocess the data for better training.\n",
        "Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network. Data normalization is done by subtracting the mean from each pixel and then dividing the result by the standard deviation. This is implemented in the `normalize(input_data)` function here.\n",
        "\n",
        "Besides, we need to convert the label for each image into a one-hot vector, which means, for example, we represent label 2 (truck) as a vector `[0, 0, 1]`, so that the model output can be directly compared with the data label. This has been implemented in the `label_to_onehot(labels)` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjgTdXv6Kh7"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xj5HNe42XO"
      },
      "source": [
        "# define our monitor\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "x_train_norm = normalize(x_train)\n",
        "x_test_norm = normalize(x_test)\n",
        "\n",
        "y_train_onehot = label_to_onehot(y_train)\n",
        "y_test_onehot = label_to_onehot(y_test)\n",
        "\n",
        "history = perceptron.fit(x_train_norm, y_train_onehot, epochs=20, validation_data=(x_test_norm, y_test_onehot), shuffle=True, callbacks=[monitor])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttqZa25BVDeR"
      },
      "source": [
        "As our model trained, it told us a few things. The most important things to us are:\n",
        "* how accurate it was when training on the training set (reported as `acc`)\n",
        "* how accurate it was on the test set (reported as `val_acc`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsOkqi035XRE"
      },
      "source": [
        "We can actually plot how how well our model did across epochs using the model's `history`!\n",
        "To do this, we call:\n",
        "```\n",
        "plot_acc(history)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOxhOg3c_lXt"
      },
      "source": [
        "plot_acc(history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}